\chapter{Quicksort} \label{chap.QuickSort}
\section{Funzionamento generale}
Quicksort è un algoritmo di ordinamento sequenziale ampiamente utilizzato grazie alla sua velocità e semplicità. Il suo nome significa "ordinamento rapido" e, infatti, è l'algoritmo di ordinamento con le prestazioni migliori, nel caso medio, tra quelli basati su confronto.
Si tratta di un algoritmo ricorsivo che sfrutta il paradigma \textit{Divide and Conquer}: prima i dati vengono scomposti ricorsivamente in base ad un valore chiave chiamato \textit{pivot}. I valori minori o uguali al pivot saranno posizionati nella parte sinistra del sottoarray considerato, mentre i valori maggiori o uguali saranno posizionati nella parte destra dello stesso. Infine i sottoarray vengono uniti per formare l'output dell'algoritmo. \\

\section{Implementazione parallela}
La nostra implementazione parallela si basa sull'algoritmo presentato in \cite{PaperQuickSort}. In questo paper viene illustrato un algoritmo parallelo ricorsivo a memoria condivisa. Questo significa che i vari processi possono comunicare e interagire direttamente tramite la modifica di variabili condivise. Si tratta di un protocollo molto diverso da quello MPI e questo ha richiesto numerose modifiche all'algoritmo. Abbiamo, inoltre, reso l'algoritmo iterativo in modo da risparmiare memoria e accelerare l'esecuzione.

Supponiamo di dover ordinare un array con $N$ elementi, indicizzati da $0$ a $N-1$. Ad ogni processore viene assegnato un indice globale, \texttt{PID}, che varia da $0$ a $P-1$ (dove $P$ è il numero di processori a disposizione).\\
L'algoritmo presentato consiste in 4 fasi:
\begin{enumerate}
\item partizionamento parallelo dei dati (\textit{Sezione \ref{subsect_Phase1}});
\item partizionamento sequenziale dei dati (\textit{Sezione \ref{subsect_Phase2}});
\item partizionamento dei processi (\textit{Sezione \ref{subsect_Phase3}});
\item ordinamento sequenziale (\textit{Sezione \ref{subsect_Phase4}}).
\end{enumerate}
 
\subsection{Fase 1: partizionamento parallelo dei dati} \label{subsect_Phase1}
L'array di input viene idealmente suddiviso in blocchi di grandezza fissa (\texttt{BLOCK\_SIZE}). Per ottenere le massime prestazioni, \texttt{BLOCK\_SIZE} deve essere tale da consentire di memorizzare 2 blocchi nella cache di un singolo processore. Nel nostro caso abbiamo scelto di impostare \texttt{BLOCK\_SIZE = 2048} per garantire un comportamento corretto ed efficiente anche con file di input non troppo grandi.

Una volta scelto un pivot (unico per tutti i processi, per dettagli sulla scelta si veda la Fase 4, \textit{Sezione \ref{subsect_Phase4}}), ogni processo preleva un blocco dall'estremità sinistra dell'array e uno da quella destra. Su questi due blocchi viene eseguita una neutralizzazione, che consiste nell'invertire gli elementi tra i due blocchi in modo che nel blocco di sinistra risultino unicamente elementi $x_i \le pivot$ e in quello di destra $x_i \ge pivot$.
Quando tutti gli elementi di almeno uno dei due blocchi rispettano la specifica precedente, la neutralizzazione è completa. A questo punto si possono presentare 3 casi:
\begin{itemize}
\item Viene neutralizzato il blocco di sinistra. In questo caso il processo preleva il primo blocco disponibile dalla parte sinistra dell'array.
\item Viene neutralizzato il blocco di destra. In questo caso viene prelevato il primo blocco disponibile dalla parte destra dell'array.
\item Vengono neutralizzati entrambi i blocchi. In questo caso il processo preleva nuovamente un blocco a sinistra e uno a destra.
\end{itemize}
Se erano disponibili blocchi sufficienti, il processo ripete la neutralizzazione con i due blocchi a sua disposizione, altrimenti termina la computazione.
Nel caso che l'array non sia divisibile per \texttt{BLOCK\_SIZE} gli elementi rimanenti vengono lasciati per la Fase 2 (\textit{Sezione \ref{subsect_Phase2}}).

La nostra implementazione, non avendo a disposizione un array condiviso, adotta un approccio Master-Slave. Il processo con \texttt{PID = 0} (rispetto al comunicatore corrente, per dettagli si veda la Fase 3, \textit{Sezione \ref{subsect_Phase3}}) ricopre il ruolo di Master, mentre gli altri diventano Slave.
Ad ogni iterazione di questa fase, se sono disponibili blocchi, questi vengono assegnati e inviati ai vari Slave. Al termine della computazione, i blocchi neutralizzati vengono inviati al Master per aggiornare l'array e tutti i processori attendono prima di iniziare una nuova iterazione.
Se non sono disponibili più blocchi, viene aggiornato anche l'ultimo blocco non neutralizzato.


\subsection{Fase 2: partizionamento sequenziale dei dati} \label{subsect_Phase2}
Lo scopo della seconda fase è terminare ciò che è stato iniziato nella Fase 1 \textit{Sezione \ref{subsect_Phase1}}, cioè suddividere gli elementi dell'array in due parti: la parte sinistra, minore o uguale del pivot, e quella destra, maggiore o uguale del pivot. Questo viene fatto dal Master della Fase 1, mentre gli altri processi attendono il risultato della computazione, che sarà il punto di stacco tra le due parti dell'array (chiamato \textit{split point}).
La Fase 2 è composta da 3 sotto-fasi:
\begin{itemize}
\item Neutralizzazione dei blocchi rimanenti (finchè possibile);
\item Spostamento dei blocchi non ancora neutralizzati nella parte centrale dell'array in modo che siano tutti contigui;
\item Partizionamento degli elementi nella parte centrale rispetto al pivot.
\end{itemize}
Al termine, lo \textit{split point} verrà comunicato a tutti i processi del comunicatore.


\subsection{Fase 3: partizionamento dei processi} \label{subsect_Phase3}
Questa fase consiste nel partizionamento dei processi in due gruppi, che ripeteranno iterativamente le fasi 1, 2 e 3, ognuno su una delle due parti in cui è stato precedentemente suddiviso l'array. Le dimensioni dei gruppi di processi sono proporzionate alle dimensioni dei sottoarray.
Definiti i gruppi, questi ripartono (ognuno sul proprio array) con la Fase 1, a meno che il gruppo non sia formato da un unico processo. In questo caso, il suddetto processo passa direttamente alla Fase 4 (\textit{Sezione \ref{subsect_Phase4}}).

Per implementare questa fase con MPI, è stato necessario adottare nuovamente un approccio Master-Slave, diverso però da quello delle fasi precedenti. Per ogni gruppo di processi, infatti, viene definito un nuovo comunicatore, che servirà per la struttura Master-Slave delle fasi 1 e 2. Nella fase 3, invece, il Master è sempre il processo 0 (che chiameremo \texttt{P0}) rispetto al comunicatore globale.

Dopo le fasi precedenti, per prima cosa  \texttt{P0} riceve gli ultimi aggiornamenti dai Master dei vari gruppi. In seguito, invia ai Master dell'iterazione successiva e ai processi in uscita dalla Fase 3 le rispettive sezioni dell'array, mentre i vari Slave attendono il nuovo inizio della Fase 1.
Anche se  \texttt{P0} rimane in gruppo solo con se stesso rimane nella Fase 3 fino all'uscita di tutti gli altri processi in modo da perpetuare la propria funzione di Master.


\subsection{Fase 4: ordinamento sequenziale} \label{subsect_Phase4}
A questo punto ogni processo procede all'applicazione della versione sequenziale di Quicksort sul proprio sottoarray e, al termine, invia i risultati a  \texttt{P0}.
Secondo \cite{PaperQuickSort}, quando un processo termina l'ordinamento della propria sezione, procede ad aiutare i processi ancora in attività nella Fase 4 accedendo direttamente alle loro variabili. 

Ottenere lo stesso livello di interazione in MPI sarebbe stato molto impegnativo dal punto di vista implementativo, quindi abbiamo scelto di lasciare che ogni processo proceda indipendentemente dagli altri. Per compensare, però, e ottenere comunque una buona suddivisione del carico, nella Fase 1 (\textit{Sezione \ref{subsect_Phase1}}) abbiamo effettuato una scelta del pivot particolarmente costosa che tiene in considerazione la media tra il massimo e il minimo valore di una sequenza di 3 elementi casuali presi dall'input.

In pratica, la suddivisione si è rivelata generalmente equa. Essendo questa, però, una scelta costosa, nell'implementazione sequenziale di Quicksort abbiamo optato per una scelta molto più rapida: la media tra il primo e l'ultimo elemento dell'array. Inoltre, per velocizzare ulteriormente la Fase 4, abbiamo adottato un approccio ibrido che, sotto un certo numero di elementi (in seguito ad analisi sperimentali questa soglia è stata posta a 30 elementi),  sfrutta Insertionsort . Questo algoritmo, infatti, ha un overhead minore di Quicksort e, per input così piccoli, risulta più rapido.

